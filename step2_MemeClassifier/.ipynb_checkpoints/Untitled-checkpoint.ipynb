{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import parameters as p\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, datasets, models\n",
    "import numpy as np\n",
    "import pickle\n",
    "import MemeDataset as md\n",
    "import MemeModel as mm\n",
    "import train_test as tt\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import help as hp\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from collections import OrderedDict\n",
    "from shutil import copyfile\n",
    "from zipfile import ZipFile\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--input_dir',help='meme directory')\n",
    "parser.add_argument('--dict_dir',help='{meme:text} dictionary')\n",
    "parset.add_argument('--dict_label',help='{meme:label} dictionary')\n",
    "\n",
    "threshold = p.threshold\n",
    "glove_dir = p.glove_dir\n",
    "input_dir = parser.input_dir\n",
    "dict_dir = parser.dict_dir\n",
    "dict_dir2 = parser.dict_label\n",
    "\n",
    "with ZipFile(glove_dir,'r') as zip:\n",
    "    zip.extract('glove.6B.50d.txt',path = '../data')\n",
    "\n",
    "vectors = []\n",
    "words = []\n",
    "word2idx = {}\n",
    "with open(\"../data/glove.6B.50d.txt\", 'r') as f:\n",
    "    for index,line in enumerate(f):\n",
    "        values = line.split()\n",
    "        words.append(values[0])\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        vectors.append(vector)\n",
    "        word2idx[values[0]] = index\n",
    "\n",
    "matrix = torch.FloatTensor(vectors)\n",
    "resnet = models.resnet50(pretrained = True) # load pretrained the resnet50 model\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1]) \n",
    "trans = transforms.Compose([transforms.Resize((224,224)),transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize(mean=p.mean,std=p.std)])\n",
    "dict_=pickle.load(open(dict_dir,'rb'))\n",
    "dict_2=pikcle.load(open(dict_dir2,'rb'))\n",
    "train_dataset = md.MemeDataset_train(input_dir,word2idx,dict_,dict_2,p.max_len,transform = trans)\n",
    "model = mm.MemeClassifier(backbone,matrix)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.00001)\n",
    "loss = nn.BCELoss() \n",
    "\n",
    "start_loss = 100000000\n",
    "for i in range(cu.num_epoch):\n",
    "    model,epoch_loss,optimizer = tt.train(model,loss,gpu,optimizer,train_dataset)\n",
    "    log = \"{}th epoch------------------- loss is: {}\".format(i+1,epoch_loss)\n",
    "    if epoch_loss < start_loss:\n",
    "        start_auc = auc # give loss new value\n",
    "        checkpoint = {'model_state': model.state_dict(),'criterion_state': loss.state_dict(), 'optimizer_state': optimizer.state_dict(),'epochs': i+1}\n",
    "        torch.save(checkpoint, '../data/checkpoint.pth')\n",
    "        start_loss = epoch_loss\n",
    "    else:\n",
    "        break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
