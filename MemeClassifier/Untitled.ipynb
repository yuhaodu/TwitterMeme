{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a file to make classification for IWT memes\n",
    "\"\"\"\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import classifier_utilities as cu\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, datasets, models\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from PIL import ImageFile\n",
    "from torch import optim\n",
    "from collections import Counter\n",
    "import regex as re\n",
    "import time\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "import bcolz\n",
    "import pickle\n",
    "from pytesseract import image_to_string\n",
    "import TwitterDataset as td\n",
    "import MemeModel as mm\n",
    "import train_validation_test_function as tvt\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import help as hp\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from collections import OrderedDict\n",
    "import parameters as \n",
    "threshold =0.31037354\n",
    "\n",
    "## Loading the pretrained word embedding matrix and backbone for model initiation\n",
    "\n",
    "glove_dir = '/data/yuhao/web_sci/meme_classifier/glove.6B/'\n",
    "vectors = bcolz.open(glove_dir + '6B.50.dat')[:]\n",
    "words = pickle.load(open(glove_dir + '6B.50_words.pkl', 'rb'))\n",
    "word2idx = pickle.load(open(glove_dir + '6B.50_idx.pkl', 'rb'))\n",
    "matrix = torch.FloatTensor(vectors)\n",
    "resnet = models.resnet50(pretrained = True) # load pretrained the resnet50 model\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1]) \n",
    "mean_1 = 0.579662\n",
    "mean_2 = 0.5555058\n",
    "mean_3 = 0.5413896\n",
    "std_1 = 0.3494197\n",
    "std_2 = 0.3469673\n",
    "std_3 = 0.35115704\n",
    "\n",
    "composed = transforms.Compose([transforms.Resize((224,224)),transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize(mean=[mean_1, mean_2, mean_3],std=[std_1, std_2, std_3])])\n",
    "\n",
    "composed_vali = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),transforms.Normalize(mean=[mean_1, mean_2, mean_3],std=[std_1, std_2, std_3])])\n",
    "\n",
    "test_root = \n",
    "\n",
    "# load test_dataset\n",
    "dict_1 =json.load(open('/data/yuhao/web_sci/meme_classifier/test/dic1.json','rb'))\n",
    "test_dataset = td.TwitterDataset3(test_root,word2idx,dict_1,cu.max_len,transform = composed_vali)\n",
    "model = mm.Meme_classifier2(backbone,matrix,cu.hidden_size2,cu.hidden_size,cu.batch_size)\n",
    "loss = nn.BCELoss()\n",
    "test_loss_p = 1000000\n",
    "index = 0\n",
    "\n",
    "def test(model, loss, gpu,dataset,threshold):\n",
    "    \"\"\"\n",
    "    This is the function for evaluating the model\n",
    "    Input: model: evaluation model\n",
    "           loader: dataloader\n",
    "           criterion: critertion for loss\n",
    "           gpu: using gpu or not (binary)\n",
    "           dataset: dataset for evaluation\n",
    "    Output: Directory_IWTmeme: \n",
    "            Directory_nonIWTmeme:\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset, batch_size = cu.batch_size, shuffle = True, num_workers = 4)\n",
    "\n",
    "    model.eval()\n",
    "    current_loss = 0\n",
    "    target = []\n",
    "    output = []\n",
    "    preds = []\n",
    "    name = []\n",
    "    for (image_,text_ ,name_) in dataloader:\n",
    "        image_,text_ = image_.cuda(),text_.type(torch.LongTensor).cuda()\n",
    "        model = model.cuda() # put data into GPU\n",
    "        output_ = model.forward(image_,text_).type(torch.FloatTensor)\n",
    "        preds.extend(1-output_.detach().cpu().numpy())\n",
    "        name.extend(list(name_))\n",
    "    preds = [True if i > threshold else False for i in preds ]\n",
    "    IWTmeme_name = [i for index,i in enumerate(name) if preds[index]]\n",
    "    nonIWTmeme_name = [i for index,i in enumerate(name) if not preds[index]]\n",
    "    return IWTmeme_name, nonIWTmeme_name\n",
    "\n",
    "\n",
    "gpu = True # use GPU or not\n",
    "model_dir = './checkpoint/model.pth'\n",
    "checkpoint = torch.load(model_dir)\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "IWTmeme_name, nonIWTmeme_name = test(model,loss,gpu,test_dataset,threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
